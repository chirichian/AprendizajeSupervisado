{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizamos los datos\n",
    "## *vemos features\n",
    "## *significado de la clasificacion 1 o 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_files('review_polarity_competition/reviews_sentoken', shuffle=False)\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target_names'][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1070.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target\n",
       "count  1070.000000\n",
       "mean      0.500000\n",
       "std       0.500234\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.500000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'data': dataset['data'], 'target': dataset['target']})\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>data_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1070.000000</td>\n",
       "      <td>1070.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1192.698131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500234</td>\n",
       "      <td>1158.666310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>450.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>798.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1532.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7577.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target     data_len\n",
       "count  1070.000000  1070.000000\n",
       "mean      0.500000  1192.698131\n",
       "std       0.500234  1158.666310\n",
       "min       0.000000    72.000000\n",
       "25%       0.000000   450.250000\n",
       "50%       0.500000   798.000000\n",
       "75%       1.000000  1532.750000\n",
       "max       1.000000  7577.000000"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data_len'] = data['data'].apply(lambda x: len(x))\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">data_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>535.0</td>\n",
       "      <td>1006.986916</td>\n",
       "      <td>1029.810276</td>\n",
       "      <td>72.0</td>\n",
       "      <td>388.5</td>\n",
       "      <td>680.0</td>\n",
       "      <td>1273.5</td>\n",
       "      <td>7577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>535.0</td>\n",
       "      <td>1378.409346</td>\n",
       "      <td>1248.164095</td>\n",
       "      <td>81.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>6897.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       data_len                                                              \n",
       "          count         mean          std   min    25%    50%     75%     max\n",
       "target                                                                       \n",
       "0         535.0  1006.986916  1029.810276  72.0  388.5  680.0  1273.5  7577.0\n",
       "1         535.0  1378.409346  1248.164095  81.0  538.0  952.0  1766.0  6897.0"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('target').describe()\n",
    "# Vemos ditribucion de cantidad de 1 y 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b\"This `` Director 's Son 's '' cut has been edited down significantly . Why ? I have no idea .\",\n",
       " b'very bad movie , one of the worst I have seen in a long time . Nuff said',\n",
       " b\"This movie was so bad , I actually fell asleep . Do n't even waste your time renting this film .\",\n",
       " b'A real tear-jerker , but a great movie . I had the movie within a week and a half',\n",
       " b\"I 'm 75 so I did n't want anything too strenuous . This is perfect for the senior .\"]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dataset['data'] if len(x) < 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# División de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "docs, X_test, y, y_test = train_test_split(\n",
    "    dataset.data,\n",
    "    dataset.target,\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "    docs,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(641, 161, 268)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_dev), len(X_test)\n",
    "#Cantidad de datos que nos queda para entrenar, para validar y para testear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 311, 1: 330}), Counter({1: 83, 0: 78}), Counter({1: 122, 0: 146}))"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train), Counter(y_dev), Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (-1, 1))\n",
    "X_dev = np.reshape(X_dev, (-1, 1))\n",
    "X_test = np.reshape(X_test, (-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificar al azar, respetando la distribución de clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=0, strategy='stratified')"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DummyClassifier(strategy='stratified', random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistencia\n",
    "Guardar en disco un modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pickle\n",
    "filename = '2018-08-15_random_baseline'\n",
    "f = open(filename, 'wb')\n",
    "pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar un modelo guardado en disco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '2018-08-15_random_baseline'\n",
    "f = open(filename, 'rb')\n",
    "clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación y Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcularemos accuracy y macro F1.\n",
    "\n",
    "En development:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.51\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.49      0.55      0.52        78\n",
      "        pos       0.53      0.47      0.50        83\n",
      "\n",
      "avg / total       0.51      0.51      0.51       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_dev)\n",
    "\n",
    "from sklearn import metrics\n",
    "acc = metrics.accuracy_score(y_dev, y_pred)\n",
    "print('accuracy\\t{:2.2f}\\n'.format(acc))\n",
    "print(metrics.classification_report(y_dev, y_pred, target_names=['neg', 'pos']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43 35]\n",
      " [44 39]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_dev, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación en test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.49\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.53      0.50      0.51       146\n",
      "        pos       0.44      0.47      0.45       122\n",
      "\n",
      "avg / total       0.49      0.49      0.49       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print('accuracy\\t{:2.2f}\\n'.format(acc))\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['neg', 'pos']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizador Bag of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from util import load_datasets\n",
    "train, _, _ = load_datasets()\n",
    "X_train, y_train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2391 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5)\n",
    "vect.fit(X_train)\n",
    "x = vect.transform(X_train[:1])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1968', 1),\n",
       " ('accent', 2),\n",
       " ('action scenes', 1),\n",
       " ('all around', 1),\n",
       " ('all start', 1),\n",
       " ('and she', 1),\n",
       " ('any', 1),\n",
       " ('apparently', 1),\n",
       " ('appears', 1),\n",
       " ('around', 1),\n",
       " ('art and', 1),\n",
       " ('at your own', 1),\n",
       " ('bbc', 1),\n",
       " ('between the two', 1),\n",
       " ('bought the dvd', 1),\n",
       " ('camera', 1),\n",
       " ('chapter', 1),\n",
       " ('comedic', 2),\n",
       " ('command', 1),\n",
       " ('compared', 3),\n",
       " ('credit', 1)]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(features[i], x[0, i]) for i in range(x.shape[1]) if x[0, i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de clasificadores y vectorizador TFID\n",
    "\n",
    "## probamos los clasificadores y vectorizadores para seleccionar aquellos que nos den una currancy mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import load_datasets\n",
    "train, dev, test = load_datasets()\n",
    "X_train, y_train = train\n",
    "X_dev, y_dev = dev\n",
    "X_test, y_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from util import print_short_eval\n",
    "\n",
    "clfs = [\n",
    "    KNeighborsClassifier(),\n",
    "    MultinomialNB(),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    LogisticRegression(random_state=0),\n",
    "    LinearSVC(random_state=0),\n",
    "    SVC(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "accuracy\t0.69\tmacro f1\t0.68\n",
      "accuracy\t0.52\tmacro f1\t0.47\n",
      "<class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "accuracy\t0.95\tmacro f1\t0.95\n",
      "accuracy\t0.80\tmacro f1\t0.79\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "accuracy\t1.00\tmacro f1\t1.00\n",
      "accuracy\t0.66\tmacro f1\t0.66\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "accuracy\t1.00\tmacro f1\t1.00\n",
      "accuracy\t0.84\tmacro f1\t0.84\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "accuracy\t1.00\tmacro f1\t1.00\n",
      "accuracy\t0.82\tmacro f1\t0.82\n",
      "<class 'sklearn.svm.classes.SVC'>\n",
      "accuracy\t0.72\tmacro f1\t0.69\n",
      "accuracy\t0.65\tmacro f1\t0.61\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "accuracy\t0.99\tmacro f1\t0.99\n",
      "accuracy\t0.77\tmacro f1\t0.77\n"
     ]
    }
   ],
   "source": [
    "# Agregamos a nuestro vectorizador el min_df= 5 seleccionado anteriormente\n",
    "vect = CountVectorizer(binary=True, min_df=5)\n",
    "\n",
    "for clf in clfs:\n",
    "    print(str(clf.__class__))\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf', clf),\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print_short_eval(pipeline, X_train, y_train)\n",
    "    print_short_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor que obtuvimos es clasificador de regresion logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "accuracy\t0.88\tmacro f1\t0.88\n",
      "accuracy\t0.76\tmacro f1\t0.76\n",
      "<class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "accuracy\t0.99\tmacro f1\t0.99\n",
      "accuracy\t0.85\tmacro f1\t0.85\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "accuracy\t1.00\tmacro f1\t1.00\n",
      "accuracy\t0.65\tmacro f1\t0.64\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "accuracy\t0.99\tmacro f1\t0.99\n",
      "accuracy\t0.84\tmacro f1\t0.84\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "accuracy\t1.00\tmacro f1\t1.00\n",
      "accuracy\t0.88\tmacro f1\t0.88\n",
      "<class 'sklearn.svm.classes.SVC'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rmartinezchi/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.51\tmacro f1\t0.34\n",
      "accuracy\t0.52\tmacro f1\t0.34\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "accuracy\t0.99\tmacro f1\t0.99\n",
      "accuracy\t0.63\tmacro f1\t0.62\n"
     ]
    }
   ],
   "source": [
    "# Ahora probamos los clasificadores pero con el vectorizador TFDF\n",
    "vect = TfidfVectorizer(binary=True)\n",
    "\n",
    "for clf in clfs:\n",
    "    print(str(clf.__class__))\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf', clf),\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print_short_eval(pipeline, X_train, y_train)\n",
    "    print_short_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obtenemos un mejor resultado con clasificador Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.88\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.89      0.85      0.87        78\n",
      "        pos       0.86      0.90      0.88        83\n",
      "\n",
      "avg / total       0.88      0.88      0.88       161\n",
      "\n",
      "[[66 12]\n",
      " [ 8 75]]\n"
     ]
    }
   ],
   "source": [
    "from util import print_eval\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(binary=True)),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.87      0.79      0.83       146\n",
      "        pos       0.77      0.86      0.81       122\n",
      "\n",
      "avg / total       0.83      0.82      0.82       268\n",
      "\n",
      "[[115  31]\n",
      " [ 17 105]]\n"
     ]
    }
   ],
   "source": [
    "print_eval(pipeline, X_test, y_test)\n",
    "from util import save_model\n",
    "save_model(pipeline, '2018-08-20_count_regrelogis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "param_grid = {\n",
    "    'vect__binary': [True],\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)],\n",
    "    'vect__min_df': [1, 3, 5, 7],\n",
    "    'vect__max_df': [0.95, 0.9, 0.7],\n",
    "    'clf__random_state': [0],\n",
    "}\n",
    "\n",
    "params_list = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(binary=True)),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "results = []\n",
    "for params in params_list:\n",
    "\n",
    "    pipeline.set_params(**params)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    result = eval(pipeline, X_dev, y_dev)\n",
    "    \n",
    "    results.append({\n",
    "        **result,\n",
    "        **params,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>clf__random_state</th>\n",
       "      <th>f1</th>\n",
       "      <th>vect__binary</th>\n",
       "      <th>vect__max_df</th>\n",
       "      <th>vect__min_df</th>\n",
       "      <th>vect__ngram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.912879</td>\n",
       "      <td>True</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.912879</td>\n",
       "      <td>True</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.912879</td>\n",
       "      <td>True</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.912473</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.912473</td>\n",
       "      <td>True</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.912473</td>\n",
       "      <td>True</td>\n",
       "      <td>0.70</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.906832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906602</td>\n",
       "      <td>True</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.906832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906312</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.906832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906312</td>\n",
       "      <td>True</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.906832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906312</td>\n",
       "      <td>True</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 5)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acc  clf__random_state        f1  vect__binary  vect__max_df  \\\n",
       "47  0.913043                  0  0.912879          True          0.70   \n",
       "48  0.913043                  0  0.912879          True          0.70   \n",
       "49  0.913043                  0  0.912879          True          0.70   \n",
       "12  0.913043                  0  0.912473          True          0.95   \n",
       "32  0.913043                  0  0.912473          True          0.90   \n",
       "52  0.913043                  0  0.912473          True          0.70   \n",
       "46  0.906832                  0  0.906602          True          0.70   \n",
       "13  0.906832                  0  0.906312          True          0.95   \n",
       "33  0.906832                  0  0.906312          True          0.90   \n",
       "34  0.906832                  0  0.906312          True          0.90   \n",
       "\n",
       "    vect__min_df vect__ngram_range  \n",
       "47             3            (1, 3)  \n",
       "48             3            (1, 4)  \n",
       "49             3            (1, 5)  \n",
       "12             5            (1, 3)  \n",
       "32             5            (1, 3)  \n",
       "52             5            (1, 3)  \n",
       "46             3            (1, 2)  \n",
       "13             5            (1, 4)  \n",
       "33             5            (1, 4)  \n",
       "34             5            (1, 5)  "
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(['acc', 'f1'], ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.91\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.92      0.90      0.91        78\n",
      "        pos       0.91      0.93      0.92        83\n",
      "\n",
      "avg / total       0.91      0.91      0.91       161\n",
      "\n",
      "[[70  8]\n",
      " [ 6 77]]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        binary=True,\n",
    "        min_df=3,\n",
    "        max_df=0.70,\n",
    "        ngram_range=(1, 3)\n",
    "    )),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluamos el modelo con el test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.85\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.88      0.84      0.86       146\n",
      "        pos       0.81      0.86      0.84       122\n",
      "\n",
      "avg / total       0.85      0.85      0.85       268\n",
      "\n",
      "[[122  24]\n",
      " [ 17 105]]\n"
     ]
    }
   ],
   "source": [
    "print_eval(pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## veamos un poco los coef que obtenemos de nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import coef_df\n",
    "df = coef_df(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12099</th>\n",
       "      <td>worst</td>\n",
       "      <td>-0.911147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>bad</td>\n",
       "      <td>-0.902214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11294</th>\n",
       "      <td>version</td>\n",
       "      <td>-0.873802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10132</th>\n",
       "      <td>the worst</td>\n",
       "      <td>-0.812003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>-0.780253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11554</th>\n",
       "      <td>waste</td>\n",
       "      <td>-0.769968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9241</th>\n",
       "      <td>terrible</td>\n",
       "      <td>-0.767895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>poor</td>\n",
       "      <td>-0.714365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11160</th>\n",
       "      <td>unfortunately</td>\n",
       "      <td>-0.692744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6337</th>\n",
       "      <td>money</td>\n",
       "      <td>-0.632748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name      coef\n",
       "12099          worst -0.911147\n",
       "1180             bad -0.902214\n",
       "11294        version -0.873802\n",
       "10132      the worst -0.812003\n",
       "2570    disappointed -0.780253\n",
       "11554          waste -0.769968\n",
       "9241        terrible -0.767895\n",
       "7655            poor -0.714365\n",
       "11160  unfortunately -0.692744\n",
       "6337           money -0.632748"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6582</th>\n",
       "      <td>must</td>\n",
       "      <td>0.614805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>great</td>\n",
       "      <td>0.616101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7507</th>\n",
       "      <td>perfect</td>\n",
       "      <td>0.630252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>especially</td>\n",
       "      <td>0.655831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>excellent</td>\n",
       "      <td>0.669917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>fantastic</td>\n",
       "      <td>0.682368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5803</th>\n",
       "      <td>life</td>\n",
       "      <td>0.695182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6848</th>\n",
       "      <td>now</td>\n",
       "      <td>0.716475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>day</td>\n",
       "      <td>0.784805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>his</td>\n",
       "      <td>0.796931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name      coef\n",
       "6582        must  0.614805\n",
       "3981       great  0.616101\n",
       "7507     perfect  0.630252\n",
       "3018  especially  0.655831\n",
       "3115   excellent  0.669917\n",
       "3246   fantastic  0.682368\n",
       "5803        life  0.695182\n",
       "6848         now  0.716475\n",
       "2366         day  0.784805\n",
       "4422         his  0.796931"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# probando con stop Word obtenemos un peor resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.85\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.88      0.81      0.84        78\n",
      "        pos       0.83      0.89      0.86        83\n",
      "\n",
      "avg / total       0.85      0.85      0.85       161\n",
      "\n",
      "[[63 15]\n",
      " [ 9 74]]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        binary=True,\n",
    "        min_df=3,\n",
    "        max_df=0.70,\n",
    "        ngram_range=(1, 3),\n",
    "        stop_words='english'\n",
    "    )),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 85 vs 91 conviene continuar sin Stop Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.91\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.92      0.90      0.91        78\n",
      "        pos       0.91      0.93      0.92        83\n",
      "\n",
      "avg / total       0.91      0.91      0.91       161\n",
      "\n",
      "[[70  8]\n",
      " [ 6 77]]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "        binary=True,\n",
    "        min_df=3,\n",
    "        max_df=0.70,\n",
    "        ngram_range=(1, 3)\n",
    "    )),\n",
    "    ('clf', LinearSVC(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listado de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for i, (x, y1, y2, y2p) in enumerate(zip(X_dev, y_dev, y_pred, y_prob)):\n",
    "    if y1 != y2:\n",
    "        errors.append({\n",
    "            'index': i,\n",
    "            'item': x,\n",
    "            'true': y1,\n",
    "            'pred': y2,\n",
    "            'diff': diff})\n",
    "\n",
    "errdf = pd.DataFrame(errors)\n",
    "errdf.sort_values('diff', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff</th>\n",
       "      <th>index</th>\n",
       "      <th>item</th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.715889</td>\n",
       "      <td>5</td>\n",
       "      <td>b\"What can I say about this uninspired `` rete...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.715889</td>\n",
       "      <td>11</td>\n",
       "      <td>b\"This is a very good movie . Do n't expect an...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.715889</td>\n",
       "      <td>12</td>\n",
       "      <td>b\"I really enjoy Lost Highway and have been wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.715889</td>\n",
       "      <td>15</td>\n",
       "      <td>b\"This is a very 70s horror flick based on the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.715889</td>\n",
       "      <td>17</td>\n",
       "      <td>b\"Tom Hanks is a great actor , but watching hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.715889</td>\n",
       "      <td>20</td>\n",
       "      <td>b\"It should have been called `` The Male Booty...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.715889</td>\n",
       "      <td>51</td>\n",
       "      <td>b\"Criterion 's release of Alfred Hitchcock 's ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.715889</td>\n",
       "      <td>119</td>\n",
       "      <td>b\"This biopic , based on John Denver 's Take M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.715889</td>\n",
       "      <td>120</td>\n",
       "      <td>b\"I am a senior citizen with bad knees from in...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.715889</td>\n",
       "      <td>129</td>\n",
       "      <td>b\"After the first installment in the Blade ser...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.715889</td>\n",
       "      <td>133</td>\n",
       "      <td>b\"I rented this knowing it was n't actually go...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.715889</td>\n",
       "      <td>144</td>\n",
       "      <td>b\"With such a talented cast and a semi-decent ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.715889</td>\n",
       "      <td>148</td>\n",
       "      <td>b'A real tear-jerker , but a great movie . I h...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.715889</td>\n",
       "      <td>157</td>\n",
       "      <td>b\"For some reason , the second Monogram Chan m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        diff  index                                               item  pred  \\\n",
       "0  -0.715889      5  b\"What can I say about this uninspired `` rete...     1   \n",
       "1  -0.715889     11  b\"This is a very good movie . Do n't expect an...     0   \n",
       "2  -0.715889     12  b\"I really enjoy Lost Highway and have been wa...     0   \n",
       "3  -0.715889     15  b\"This is a very 70s horror flick based on the...     1   \n",
       "4  -0.715889     17  b\"Tom Hanks is a great actor , but watching hi...     1   \n",
       "5  -0.715889     20  b\"It should have been called `` The Male Booty...     1   \n",
       "6  -0.715889     51  b\"Criterion 's release of Alfred Hitchcock 's ...     0   \n",
       "7  -0.715889    119  b\"This biopic , based on John Denver 's Take M...     1   \n",
       "8  -0.715889    120  b\"I am a senior citizen with bad knees from in...     0   \n",
       "9  -0.715889    129  b\"After the first installment in the Blade ser...     0   \n",
       "10 -0.715889    133  b\"I rented this knowing it was n't actually go...     1   \n",
       "11 -0.715889    144  b\"With such a talented cast and a semi-decent ...     1   \n",
       "12 -0.715889    148  b'A real tear-jerker , but a great movie . I h...     0   \n",
       "13 -0.715889    157  b\"For some reason , the second Monogram Chan m...     1   \n",
       "\n",
       "    true  \n",
       "0      0  \n",
       "1      1  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  \n",
       "5      0  \n",
       "6      1  \n",
       "7      0  \n",
       "8      1  \n",
       "9      1  \n",
       "10     0  \n",
       "11     0  \n",
       "12     1  \n",
       "13     0  "
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "What can I say about this uninspired `` retelling '' of Bret 's first novel ? The film adaptation does n't contain the scenes and the tone I thought made the book so haunting and memorable . ( The dead boy in the alley scene , the snuff film with the underage girl ... ) This film really ca n't be claimed that it is based on the book - it 's more that it 's inspired by the novel . Despite this downfall , the film is worth watching for any Bret Easton Ellis fan - if only to satisfy one 's curiosity.The film contains neither the perfectly depressing one-liners or the delightfully disturbing minor characters that make the book so interesting and engaging ( Clay 's sisters , Spin ) The film made it seem as though Julian was the protagonist , while I always felt the novel was all about seeing the events unfold through Clay 's eyes . One of the more endearing parts of the novel are Clay 's 'flashbacks ' of a better time , before he left for school . The film only touches on this in the beginning , and the flashback is about Blair , not about his parents , who which were the subjects of the flashbacks I found the most interesting . The lunch scene between Clay and his father is pure genius . The detachment between the father and son made me physically cringe . This scene is not included in the film at all.The unfortunate thing about adapting films from books is that something is almost always lost in the 'translation ' . 'American Psycho ' is really the only one of the films adapted from his books that I feel captures the tone of the book while simultaneously compacting it into a watchable narrative without losing Bret 's style , and this is due to the fact that Bateman himself is the narrator.All and all , 'Less Than Zero ' is n't a bad film , really . Just a bad adaptation . It captures what was both awesome and forgettable about 80s popular film , and fits the bill of any entertaining teen drama from that era ( Including extravagant cocaine use by minors , too much New Wave , the once-hot but potential future star of Where Are They Now ? James Spader ) . There are some touching moments , but it seems as though the film tried to hard find a conclusion the book did n't ( and had a reason for not doing ) . After all , Julian does n't die in the novel , and Blair certainly does n't go back to Camden with Clay ( Morrissey would n't be proud ) .What 's so melancholy about the novel is what the film failed to allude too : how upset , apathetic , nd lost Clay is now that he has changed and gained a new perspective , while his friends , sadly , have not.And one serious complaint : Where is the Disappear Here billboard ? It 's integral to the imagery of the novel , and is absent in the film ( unless I missed it . ) All and all : If you 're a fan of Bret 's books , give this film a shot . It 's worth watching once , but do n't be upset if it hardly even attempts to capture the mood or purpose of the novel .\n",
      "\n",
      "\n",
      "11\n",
      "This is a very good movie . Do n't expect any good guys here . If you want a hero with a bit of soul watch the Silvester Stallone remake a movie I also like . Both movies have a lot of action .\n",
      "\n",
      "\n",
      "12\n",
      "I really enjoy Lost Highway and have been waiting years for this 2008 DVD release . I avoided buying the previous 'import ' version due to the explicit consumer complaints regarding the quality of the transfer . My potential concerns regarding sound and picture quality were allayed upon viewing this new U.S. release . It looks and sounds quite good , bearing in mind the source material . The visual style of the film is sparse , simple , and high-contrast -- rendered with Lynch 's `` vague America '' aesthetic . The image maintains its integrity and the deep blacks employed do not suffer from noise often seen in older or poor transfers ; the colors are also solid for a DVD . The sound design is suitably moody , ambient , dark , evocative , provocative , and intersperses a fairly eclectic mixture of songs with the invaluable contributions of composer Angelo Badalamenti . There can be a slightly irritating difference in volume between Patricia Arquette 's near-whispering and , say , Rammstein -- but this is not an uncommon problem with DVDs . Otherwise it sounds pretty cool.I 'm not going to review the film but I will say the complete lack of special features is more forgivable for such an unusual , ambiguous , and artistic film as Lost Highway than any other movie I can think of right now . I tend to view this film the way I view abstract art : explanation is not only unwarranted but also largely undesirable . In other words , special features could be intriguing but I hardly miss them for a movie like Lost Highway .\n",
      "\n",
      "\n",
      "15\n",
      "This is a very 70s horror flick based on the bestselling book of the 'true ' story of a haunted Long Island home . It was debunked and proven to be a total sham , but the film spawned about ten sequels and even that necessary remake.The Lutz family purchases their dream house only to find that it 's haunted , and also helpfully contains the passageway to Hell in the basement . Yes , it is completely and utterly crushing to think that if such a passage existed into something called Hell , it would be in Amityville , Long Island.James Brolin plays the husband , tough guy with a lot of hair . Margot Kidder is the wife , who gets to react with big , wide eyes whenever she witnesses a ghost , hallucination , atrocity , etc . Most of the scares are indeed opening doors or something , looking at something , and then the music gets really loud , and then we see the peoples ' eyes , closer , and then , da-da ! A cheesy special effect.Good for nostalgia value . The appearance of Rod Steiger as a crazed priest is a major plus . Like a cheap Exorcist . If these types of films scare you , it might be worth it on a slow night . Good for some unintentional laughs , too .\n",
      "\n",
      "\n",
      "17\n",
      "Tom Hanks is a great actor , but watching him talk to himself for all that time almost made me wish he had hung himself in the movie , which should have saved me at least a good 35 minutes of my life wasted watching this movie . It was a good concept , but the final execution of watching Hanks and Wilson the Volleyball survive all those years on the island to have the moral of the story be that time marches on whether your around or not ... let 's just say it was a letdown .\n",
      "\n",
      "\n",
      "20\n",
      "It should have been called `` The Male Booty Movie '' ! Every ten minutes some guy is showing his butt . Either he 's getting busy with a woman or mastering his domain . Do n't get me wrong : long live men 's butts ! Still , this sure had a lot of them , especially for a non-rainbow-flag film . If you like the male buttocks , then here 's some excellent eye candy for you . Happy New Year ! ! !\n",
      "\n",
      "\n",
      "51\n",
      "Criterion 's release of Alfred Hitchcock 's Spellbound has a slight flaw . 74 minutes into the film we get a shot of J.B. ( Gregory Peck ) holding a razor blade , whilst hearing Brulov 's ( Michael Checkov 's ) line off screen 'Is that you Mr Brown ? 'We then cut to Brulov for his next line 'Oh I thought it was you . ' Simple , no ? Well , the Criterion DVD cuts away from the razor blade too soon , and thenhas the footage of Brulov mouthing his 2nd line , whilst overdubbing his ! st ! Then we get the 2nd line properly . In other words , the footage of Brulov 's line'Oh I thought it was you ' is spliced together twice ! ! So far I do n't know if the Criterion disc is the only version affected.If you do n't mind the glitch , then Criterion 's version of Spellbound is the version to collect ( great extras and picture quality ) . And if you can still find it somewhere ( since it 's now Out of Print ) do n't hesitate to buy it , it 's still a very good disc and those extras really make this DVD into a true collector 's item . Just do n't throw away that old VHS tape !\n",
      "\n",
      "\n",
      "119\n",
      "This biopic , based on John Denver 's Take Me Home , An Autobiography , will be enjoyed by hardcore fans ( like me ) but is still awful in many ways . The story begins in the early 60s as John ( Chad Lowe ) begins his folk singing career . He meets Annie ( Kristin Davis ) at a gig and falls in love on the spot . They marry and move to Aspen , but as John 's career takes off , tension builds in the marriage . They divorce , he has a short second marriage , and he discovers his love of flying , something that finally earns his stern father 's ( Gerald McRaney ) respect.This movie is a Cliffs Notes summary of John 's life ; it 's poorly-written and amateurish and lacks any depth or emotion . Lowe ( who dons a hideous clown wig that makes him look like Dana Carvey in `` Waynes World '' ) mugs shamelessly throughout , playing a leering innocent who never seems to grow up . ( In fact , though the film covers thirty years , no one ages . ) Davis is very pretty but the horrible script does n't give her much chance to develop . McRaney plays the only character who seems real , and he 's the villain of the piece.The story is shallow and Lowe 's Denver is n't particularly likeable . His hair is so laughable and distracting that the movie does n't have a chance . Although we hear Denver sing many of his songs , Lowe is terrible at lip-syncing . The DVD extras are worthless ; where 's some footage of the real JD we loved ?\n",
      "\n",
      "\n",
      "120\n",
      "I am a senior citizen with bad knees from injuries . I can do almost all of these exercises and hope that with time , I 'll be able to do them all though I do n't know if I 'll ever be able to do things that puts pressure on my kneecaps . I 'm modifying those that are too much at this point . It 's easy to fit these strengthening exercises into my early morning schedule without a lot of fuss . And boy can I see the results .\n",
      "\n",
      "\n",
      "129\n",
      "After the first installment in the Blade series , I was really looking forward to the sequel - and I was n't dissapointed . This far surpasses Blade and just hightens the suspense for Blade : Trinity ( out Dec 10 ) . Wesley Snipes is his usual great self in a fast-paced , suspense action movie . Kris Kristofferson is brilliant as Whistler once again ( as are the rest of the cast ) . If you liked the first then you will definetly like this - and hopefully like me you cant wait for Blade : Trinity !\n",
      "\n",
      "\n",
      "133\n",
      "I rented this knowing it was n't actually gon na have a real fight of Bruce Lee and Jackie Chan , just a lotta clips . But I 'm 18 years old , still in high school , and have editing equipment and I could of made a whole lot better film than this . Honestly , what is this ? It 's downright horrible . You see Jackie Chan in Young Master and then Twin Dragons , and that 's it ! Than a little bit of Bruce Lee in about 2 or maybe 3 films and that 's it ! It never even shows them off , you only see Jackie do one descent stunt when he runs over the car and that 's it , where as a real film on this subject would show just about all his big stunts . And everyone knows Enter the Dragon is the place where to find some of Bruce Lee 's best work , and you do n't see anything from it . WHAT IS THIS ?\n",
      "\n",
      "\n",
      "144\n",
      "With such a talented cast and a semi-decent story , you think it would have been a great movie . Richard Gere plays a gynecologist in a large Texas town . His life is on the down side and he is close to having a nervous breakdown . His wife is going crazy . One of his daughters might be a lesbian and the other is just mean . He does n't know what to do . That 's when golf pro Helen Hunt moves to town and he is immediately infatuated with her . I love Robert Altman . He is a great story teller , but there was something missing from this film . If you truly love Altman , then take the time to watch it ... if you normally do n't , then you might want to steer clear from it .\n",
      "\n",
      "\n",
      "148\n",
      "A real tear-jerker , but a great movie . I had the movie within a week and a half\n",
      "\n",
      "\n",
      "157\n",
      "For some reason , the second Monogram Chan movie is a bit slow moving during the first half of the film . Mantan Moreland 's comedy material is not very good this time , but would improve in The Scarlet Clue and The Shanghai Cobra . Chan and Number 3 son Tommy get captured and roughed up this time , unusual in a Chan film . I would call this a middling effort from Monogram . Classic Chan line is & quot ; Expert is merely man who make quick decision -- and is sometimes right. & quot ;\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for error in errdf['index']:\n",
    "    print(error)\n",
    "    x = X_dev[error]\n",
    "    print(x.decode('utf-8'))\n",
    "    print('\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sitando algunos de los errores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizando alguno de los errores vemos que al modelo le esta costando identificar las ironías. Si la idea es clara como \"this is a very good movie\" no tiene problema. Pero luego las palabras siguiente tienen mayor peso aunque en la oracion no deberian tener mayor importancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([\"This is a very good movie . \"\n",
    "                  \"Do n't expect any good guys here . \"\n",
    "                  \"If you want a hero with a bit of soul watch the Silvester Stallone remake a movie I also like . \"\n",
    "                  \"Both movies have a lot of action \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([\"This is a very good movie . \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([\"This is a very good movie . \"\n",
    "                  \"Do n't expect any good guys here . \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([\"If you want a hero with a bit of soul watch the Silvester Stallone remake a movie I also like . \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([\"Both movies have a lot of action \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
